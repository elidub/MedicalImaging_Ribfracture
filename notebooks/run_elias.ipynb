{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(1, sys.path[0] + '/..')\n",
    "from src.data.datamodule import DataModule\n",
    "from src.model.setup import setup_model\n",
    "from src.misc.utils import set_seed_and_precision\n",
    "\n",
    "from src.run import parse_option, main\n",
    "args = parse_option(notebook=True)\n",
    "args.data_dir = '../data_dev'\n",
    "args.version = 'version_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/elias/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name | Type    | Params\n",
      "---------------------------------\n",
      "0 | net  | UNet3D  | 5.0 M \n",
      "1 | loss | BCELoss | 0     \n",
      "---------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.089    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elias/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elias/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:22<00:00,  5.61s/it, v_num=on_1, train_loss=0.600, train_acc=0.967, val_loss=0.669, val_acc=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:22<00:00,  5.62s/it, v_num=on_1, train_loss=0.600, train_acc=0.967, val_loss=0.669, val_acc=0.993]\n"
     ]
    }
   ],
   "source": [
    "args.train, args.predict = True, False\n",
    "args.splits = ['train', 'val']\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_dev/boxes/predict/labels/RibFrac424/patch38/box1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/elias/Documenten MBA/Studie/AIMedicalImaging/notebooks/run_elias.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/run_elias.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m args\u001b[39m.\u001b[39mtrain, args\u001b[39m.\u001b[39mpredict \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/run_elias.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m args\u001b[39m.\u001b[39msplits \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/run_elias.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m main(args)\n",
      "File \u001b[0;32m~/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/run.py:63\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     trainer\u001b[39m.\u001b[39mfit(model,  datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m     62\u001b[0m \u001b[39melif\u001b[39;00m args\u001b[39m.\u001b[39mpredict:\n\u001b[0;32m---> 63\u001b[0m     preds \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mpredict(model, datamodule\u001b[39m=\u001b[39;49mdatamodule) \u001b[39m# i think this is a (list [#batches], tuple [prediction ???], tensor [batchsize, x, y, z]) \u001b[39;00m\n\u001b[1;32m     64\u001b[0m     pred_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(args\u001b[39m.\u001b[39mlog_dir, args\u001b[39m.\u001b[39mnet, args\u001b[39m.\u001b[39mversion)\n\u001b[1;32m     65\u001b[0m     \u001b[39m# save preds in pred_dir as pickle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:852\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    851\u001b[0m _verify_strategy_supports_compile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 852\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    853\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    854\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:894\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, predict_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m    891\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    892\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m )\n\u001b[0;32m--> 894\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    896\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    897\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m-> 1018\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1020\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/loops/prediction_loop.py:110\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         batch, batch_idx, dataloader_idx \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    111\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_step(batch, batch_idx, dataloader_idx)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py:126\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches\n\u001b[1;32m    124\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    125\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n\u001b[1;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[39m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py:58\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_profiler()\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py:285\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    284\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator)\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    287\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py:123\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterators[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    124\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idx\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/data/dataset.py:90\u001b[0m, in \u001b[0;36mBoxesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m x, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m# return -1 as dummy label for test set\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_path, box))\n\u001b[1;32m     91\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(y)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform: y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(y)\n",
      "File \u001b[0;32m~/anaconda3/envs/ribfrac/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_dev/boxes/predict/labels/RibFrac424/patch38/box1.npy'"
     ]
    }
   ],
   "source": [
    "args.train, args.predict = False, True\n",
    "args.splits = ['predict']\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = os.path.join(args.log_dir, args.net, args.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preds.pkl from pred_dir\n",
    "with open(os.path.join(pred_dir, 'preds.pkl'), 'rb') as f:\n",
    "    preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]]],\n",
       " \n",
       " \n",
       "         [[[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]]],\n",
       " \n",
       " \n",
       "         [[[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]],\n",
       " \n",
       "          [[0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           ...,\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870],\n",
       "           [0.4870, 0.4870, 0.4870,  ..., 0.4870, 0.4870, 0.4870]]]]),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 7.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 2.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 2.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 2., 2.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribfrac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
