{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "sys.path.insert(1, sys.path[0] + '/..')\n",
    "from src.data.datamodule import DataModule\n",
    "from src.model.setup import setup_model\n",
    "from src.misc.utils import set_seed_and_precision\n",
    "from src.misc.files import read_image\n",
    "from src.data.utils import pad_tensor, pad_list\n",
    "\n",
    "from src.run import parse_option\n",
    "args = parse_option(notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 34, 18)\n",
      "(21, 36, 19)\n",
      "(20, 37, 21)\n",
      "(21, 29, 19)\n",
      "(12, 15, 9)\n",
      "(26, 24, 20)\n",
      "(2, 11, 5)\n",
      "(14, 16, 4)\n",
      "(15, 16, 10)\n",
      "(16, 29, 17)\n",
      "(21, 23, 14)\n",
      "(20, 36, 12)\n"
     ]
    }
   ],
   "source": [
    "x_path = '../data_dev/boxes/train/images/'\n",
    "y_path = '../data_dev/boxes/train/labels/'\n",
    "for file in os.listdir(x_path):\n",
    "    patches = os.listdir(os.path.join(x_path, file))\n",
    "    for patch in patches:\n",
    "        boxes = os.listdir(os.path.join(x_path, file, patch))\n",
    "        for box in boxes:\n",
    "            x = np.load(os.path.join(x_path, file, patch, box))\n",
    "            y = np.load(os.path.join(y_path, file, patch, box))\n",
    "            print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tensor(torch.from_numpy(x)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, _ = read_image('../data_dev/train/images/RibFrac422-image.nii.gz') \n",
    "label_data, header = read_image('../data_dev/train/labels/RibFrac422-label.nii.gz')\n",
    "\n",
    "x = image_data\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "y = label_data\n",
    "y = np.where(y > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = np.where(y == 1)\n",
    "\n",
    "# for coord, coord_name in zip(coords, ['x', 'y', 'z']):\n",
    "#     plt.hist(coord, bins=50, label = coord_name, alpha = 0.5)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 50, 81) 1387\n",
      "(100, 100, 101) 16372\n"
     ]
    }
   ],
   "source": [
    "coords = [\n",
    "    [[300, 420], [200, 250], [30, 111]],\n",
    "    [[400, 500], [150, 250], [100, 201]],\n",
    "]\n",
    "\n",
    "def coord_slice(x, coord):\n",
    "    c = tuple([slice(*coord_xyz) for coord_xyz in coord])\n",
    "    return x[c]\n",
    "\n",
    "for coord in coords:\n",
    "    y_slice = coord_slice(y, coord)\n",
    "    print(y_slice.shape, y_slice.sum())\n",
    "\n",
    "\n",
    "x0 = coord_slice(x, coords[0])\n",
    "y0 = coord_slice(y, coords[0])\n",
    "x1 = coord_slice(x, coords[1])\n",
    "y1 = coord_slice(y, coords[1])\n",
    "\n",
    "x0 = torch.from_numpy(x0).float()\n",
    "y0 = torch.from_numpy(y0).float()\n",
    "x1 = torch.from_numpy(x1).float()\n",
    "y1 = torch.from_numpy(y1).float()\n",
    "\n",
    "x_unpadded = [x0, x1]\n",
    "y_unpadded = [y0, y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x_unpadded, padding_value = 0, size = 64):\n",
    "    return torch.stack([nn.functional.pad(x, (\n",
    "            0, size - x.shape[-1],\n",
    "            0, size - x.shape[-2], \n",
    "            0, size - x.shape[-3]\n",
    "        ), value = padding_value) for x in x_unpadded])\n",
    "\n",
    "x_padded = pad(x_unpadded)\n",
    "y_padded = pad(y_unpadded)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for i, x_i in enumerate(x_padded):\n",
    "        torch.save(x_i, f'../data_boxes/{split}/images/{i}.pt')\n",
    "\n",
    "    for i, y_i in enumerate(y_padded):\n",
    "        torch.save(y_i, f'../data_boxes/{split}/labels/{i}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribfrac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
