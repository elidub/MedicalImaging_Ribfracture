{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad' from 'src.data.utils' (/Users/elias/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/data/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/elias/Documenten MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m1\u001b[39m, sys\u001b[39m.\u001b[39mpath[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/..\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatamodule\u001b[39;00m \u001b[39mimport\u001b[39;00m DataModule\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msetup\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elias/Documenten%20MBA/Studie/AIMedicalImaging/notebooks/unet_elias.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed_and_precision\n",
      "File \u001b[0;32m~/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/data/datamodule.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensor\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m CustomImageDataset, BoxesDataset\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDataModule\u001b[39;00m(pl\u001b[39m.\u001b[39mLightningDataModule):\n\u001b[1;32m      9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mdir\u001b[39m, dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m, batch_size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, num_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/data/dataset.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m1\u001b[39m, sys\u001b[39m.\u001b[39mpath[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/..\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m pad\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image\u001b[39m(file_path):\n\u001b[1;32m     14\u001b[0m     nii_img \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mload(file_path)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pad' from 'src.data.utils' (/Users/elias/Documenten MBA/Studie/AIMedicalImaging/notebooks/../src/data/utils.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "sys.path.insert(1, sys.path[0] + '/..')\n",
    "from src.data.datamodule import DataModule\n",
    "from src.model.setup import setup_model\n",
    "from src.misc.utils import set_seed_and_precision\n",
    "from src.misc.files import read_image\n",
    "from src.data.utils import pad_tensor, pad_list\n",
    "\n",
    "from src.run import parse_option\n",
    "args = parse_option(notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 34, 18)\n",
      "(21, 36, 19)\n",
      "(20, 37, 21)\n",
      "(21, 29, 19)\n",
      "(12, 15, 9)\n",
      "(26, 24, 20)\n",
      "(2, 11, 5)\n",
      "(14, 16, 4)\n",
      "(15, 16, 10)\n",
      "(16, 29, 17)\n",
      "(21, 23, 14)\n",
      "(20, 36, 12)\n"
     ]
    }
   ],
   "source": [
    "x_path = '../data_dev/boxes/train/images/'\n",
    "y_path = '../data_dev/boxes/train/labels/'\n",
    "for file in os.listdir(x_path):\n",
    "    patches = os.listdir(os.path.join(x_path, file))\n",
    "    for patch in patches:\n",
    "        boxes = os.listdir(os.path.join(x_path, file, patch))\n",
    "        for box in boxes:\n",
    "            x = np.load(os.path.join(x_path, file, patch, box))\n",
    "            y = np.load(os.path.join(y_path, file, patch, box))\n",
    "            print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, _ = read_image('../data_dev/train/images/RibFrac422-image.nii.gz') \n",
    "label_data, header = read_image('../data_dev/train/labels/RibFrac422-label.nii.gz')\n",
    "\n",
    "x = image_data\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "y = label_data\n",
    "y = np.where(y > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = np.where(y == 1)\n",
    "\n",
    "# for coord, coord_name in zip(coords, ['x', 'y', 'z']):\n",
    "#     plt.hist(coord, bins=50, label = coord_name, alpha = 0.5)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 50, 81) 1387\n",
      "(100, 100, 101) 16372\n"
     ]
    }
   ],
   "source": [
    "coords = [\n",
    "    [[300, 420], [200, 250], [30, 111]],\n",
    "    [[400, 500], [150, 250], [100, 201]],\n",
    "]\n",
    "\n",
    "def coord_slice(x, coord):\n",
    "    c = tuple([slice(*coord_xyz) for coord_xyz in coord])\n",
    "    return x[c]\n",
    "\n",
    "for coord in coords:\n",
    "    y_slice = coord_slice(y, coord)\n",
    "    print(y_slice.shape, y_slice.sum())\n",
    "\n",
    "\n",
    "x0 = coord_slice(x, coords[0])\n",
    "y0 = coord_slice(y, coords[0])\n",
    "x1 = coord_slice(x, coords[1])\n",
    "y1 = coord_slice(y, coords[1])\n",
    "\n",
    "x0 = torch.from_numpy(x0).float()\n",
    "y0 = torch.from_numpy(y0).float()\n",
    "x1 = torch.from_numpy(x1).float()\n",
    "y1 = torch.from_numpy(y1).float()\n",
    "\n",
    "x_unpadded = [x0, x1]\n",
    "y_unpadded = [y0, y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x_unpadded, padding_value = 0, size = 64):\n",
    "    return torch.stack([nn.functional.pad(x, (\n",
    "            0, size - x.shape[-1],\n",
    "            0, size - x.shape[-2], \n",
    "            0, size - x.shape[-3]\n",
    "        ), value = padding_value) for x in x_unpadded])\n",
    "\n",
    "x_padded = pad(x_unpadded)\n",
    "y_padded = pad(y_unpadded)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for i, x_i in enumerate(x_padded):\n",
    "        torch.save(x_i, f'../data_boxes/{split}/images/{i}.pt')\n",
    "\n",
    "    for i, y_i in enumerate(y_padded):\n",
    "        torch.save(y_i, f'../data_boxes/{split}/labels/{i}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribfrac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
